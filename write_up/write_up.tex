\documentclass[a4paper, oneside, twocolumn]{article}
\usepackage[margin=0.7in]{geometry}
\usepackage{lmodern}
\usepackage{caption,setspace}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{authblk}
\usepackage{eso-pic,lipsum}
% Massively reduces whitespace.
% \usepackage{savetrees}
% For tables.
\usepackage{booktabs}
\setlength{\heavyrulewidth}{1pt}
\setlength{\abovetopsep}{3pt}
% Increase space between columns.
\setlength\columnsep{20pt}
% For referencing.
\usepackage[backend=biber, natbib=true, style=numeric, sorting=none]{biblatex}
\addbibresource{write_up.bib}
% Make captions look different to regular text.
\captionsetup{font={footnotesize, sf}, labelfont=bf, width=\columnwidth}

\begin{document}
\title{\huge Latent Dimensionality Reduction: An Algorithmic Method for Interpreting Black Box Models \\
\Large \emph{DRAFT}}
\author[1]{Elias Kassell}
\author[2]{Fred Farrell}

\affil[1]{\href{mailto:eliaskassell@gmail.com}{eliaskassell@gmail.com}}
\affil[2]{\href{mailto:ffarrell@illumina.com}{ffarrell@illumina.com}}
\date{September 2019}
\maketitle

\section{Abstract}\label{abstract}

LDR (Latent Dimensionality Reduction) is an algorithmic method for interpreting models by decomposing predictions from the original high dimensional feature space into a lower dimensional space. Both the output of the model and the certainty of its predictions are encoded in the condensed space. The method works out of the box on both classification and regression problems with input features relating to interpretable metrics. The output gives the ability to glimpse higher dimensional spaces, which are normally too complex for humans to understand, and is a powerful tool in understanding the underlying features generating the metrics.

\section*{Acknowledgements}

Thanks to Illumina\textsuperscript{\textregistered} for supporting this research. The extremely high dimensional problems posed by genomic analysis provided the inspiration for this work.

\section{Introduction}\label{Introduction}

When training a model to make predictions in situations where interpretability is not required, the main goal is to maximise predictive accuracy \cite{breiman2001statistical}. Often black box models have a higher predictive accuracy than more interpretable solutions, particularly in higher dimensional or more complex problems \cite{schmidhuber2015deep}. Because of the uninterpretability of these models, they become impractical for situations where it is a necessity to understand why a model has chosen a particular output as its prediction, and what effect changes to values of the input features will have on the output of the model.

Some examples generic uses of model interpretation in real world applications include

\begin{enumerate}
\item Understanding the quality of a systems current understanding \cite{amershi2011effective}. 

\item Interpreting how the value of a feature, or subset of features, affects a model's prediction (henceforth referred to as "feature interpretation"). For example, in a medical setting this interpretation can be used for suggesting the relation between features and a diagnosis. In another example, for manufacturing this interpretation can provide target values for the underlying processes involved in quality of produce.

\item The ability to use a model when not all values for the input features are present. By integrating across features which are not present, the certainty of a model's prediction can be estimated. Current methods, such as imputing values for features which are not present, ignores the variability of the absent features across the feature space, which LDR can provide.
\end{enumerate}

\section{The Algorithm}

\begin{enumerate}
\item Scale the original data so it falls into [0, 1] intervals.
\item Train a predictive model on the scaled data.
\item \textit{(Optional)} \footnote{\textit{(Optional)} here indicates that this is a sensible step when using typical predictive models. These steps are however not necessary as LDR can be used to estimate reduced dimensionality across any space.} Train an outlier detection predictive model on the scaled data.
\item Create a KDE (kernel density estimate) \cite{parzen1962estimation} of the training samples with a bandwidth $h$ (In most cases this is best set equal to $\frac{1}{r}$). \textit{(Optional)} to improve the visualization, normalize the training to produce a constant density output.
\item Sample $n$ new points from the kernel density, using the predictive model to make a prediction at each point. \textit{(Optional)} Weight the prediction according to the outlier classifier, where outliers have no model certainty in the prediction at that point.
\item Bin the samples according to regular intervals. For each dimension, group points with resolution $r$, reducing the value of the bin to the mean prediction across it.
\end{enumerate}

\section{Generated Data Classification Example}

5000 samples are generated for two features from a 2 dimensional normal distribution with a mean of 0.5 and standard distribution of $\frac{1}{6}$, with any values outside the unit interval being scaled to the closest value in the interval. The KDE of each feature can be seen in figure \ref{fig:gen-kde}. Classes are assigned by splitting the \textit{Normal 1} feature in two, with one class falling to the left side of the peak and the other to the right. The data is then split across a 0.7/0.3 training/testing split. A single DT (decision tree) achieved an unsurprising accuracy of 100\%. 

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/gen_kde.png}
\caption{KDE (bandwidth $\frac{1}{r = 50}$) of generated normal distributions, $\mu = 0.5$, $\sigma = \frac{1}{6}$.}
\label{fig:gen-kde}
\end{figure}

Applying LDR with a resolution of 50 to the raw decision tree prediction results in the model interpretation shown in figure \ref{fig:gen-dt}. An IF (Isolation Forest) \cite{liu2008isolation} with a dynamically learned frontier was trained for outlier detection, which resulted in the outlier interpretation shown in figure \ref{fig:gen-if}. Interpolationg the DT and IF, as defined in \ref{interpolation}, resulted in in the interpretation shown in figure \ref{fig:gen-dt-if}. This shows how the \textit{Normal 1} feature by itself can be a strong indicator of model prediction, while the \textit{Normal 2} feature has little effect on the prediction by itself. Inspecting the predictions across the entire feature space gives the scatter plot shown in figure \ref{fig:gen-scat}, showing that LDR is not really necessary for interpreting the model in this scenario; the next examples demonstrate how LDR fares on difficult to interpret models.

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/gen_dt.png}
\caption{DT model prediction of generated data KDE samples. Red is certainty of class 1, blue certainty of class 2, yellow uncertainty, and grey a lack of samples in the KDE space. The top and left bar graphs are the single dimensional decomposition, while the bottom right is the two dimensional decomposition. In the single dimension estimates, the resulting value is shifted down by 0.5 to create a flat midpoint for the bars. The axis are labelled with the relative input minumum and maximum values used for scaling.}
\label{fig:gen-dt}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/gen_if.png}
\caption{IF model prediction of generated data KDE samples. Red is certainty of outliers, and blue certainty of not outliers.}
\label{fig:gen-if}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/gen_dt_if.png}
\caption{DT and IF model interpolation prediction of generated data KDE samples.}
\label{fig:gen-dt-if}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{img/gen_scat.png}
\caption{Naive scatter plot of model predictions on raw generated data.}
\label{fig:gen-scat}
\end{figure}

\section{Classification Example}

The Wisonsin breast cancer dataset \cite{breastcancer} (provided by Scikit \cite{pedregosa2011scikit}) is used as it has 31 dimensions, a significant number. The aim with the dataset is to classify the tumor as either malignant or benign. There are 569 samples in total, with 357 benign and 212 malignant.

\subsection{Random Forest and Isolation Forest Interpolation}

A 100 estimator RF (Random Forest) \cite{liaw2002classification} achieved an F1 score of 0.975, while an IF with a dynamically learned frontier was trained for outlier detection. Benign was selected as the positive category, resulting in a value of 1.0 indicating benign tumors and 0.0 inidicating malignant. All of the data is min-max scaled, then a 0.7/0.3 training/testing data split is applied. LDR is applied to the training data, integrating over 50,000 randomly selected points from the weighted kernel density of the sample space with a resolution of 50. Mean symmetry and mean area are selected for visual inspection of their individual effect on the model's classification. The certainty of the RF is shown in figure \ref{fig:interp-rf}, while the certianty of the IF is shown in figure \ref{fig:interp-if}. The final combined certainty is shown in figure \ref{fig:interp-rf-if}.

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/interp_rf.png}
\caption{RF prediction certainty, where red indicates certaincy of malignancy, and blue certainty of benality.}
\label{fig:interp-rf}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/interp_if.png}
\caption{IF prediction certainty, where red indicates certianty of outlier, blue certainty of not outlier, and yellow uncertainty.}
\label{fig:interp-if}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/interp_rf_if.png}
\caption{RF with IF interpolation prediction certainty, where red indicates overall certainty of malignancy, blue indicates overall certainty of benality, and yellow general overall uncertainty.}
\label{fig:interp-rf-if}
\end{figure}

\subsection{Neural Network and IF Interpolation}

A 3 layer feed forward Neural Network (NN) was used (via PyTorch \cite{paszke2017automatic}), consisting of an input layer, a hidden layer where tanh is applied, and an output layer. Softmax is applied when making predictions, and the final certainty of the prediction is calculated by calculating the proportion of the largest weighted class out of all weightings. The NN was trained over 50,000 epochs and achieved an F1 score of 0.961, slightly worse than the RF. The resulting LDR of the same features can be seen in figure \ref{fig:interp-nn-if}

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{img/interp_nn_if.png}
\caption{NN with IF interpolation prediction certanty.}
\label{fig:interp-nn-if}
\end{figure}

\subsection{Analysis of Discrepancy Between RF and NN}

There is very little discrepancy between the two LDR representations, both of which have similar predictive success. This is significant because random forests are widely regarded as more interpretable than neural networks \cite{song2013random}, but LDR represents them both in an equally interpretable fashion. The only visual difference between the two LDR representation arises from the NN tending to be more certain of its classifications. This can be seen in the scatter plots of prediction certainties for mean symmetry of the RF in figure \ref{fig:rf-if-mean-symmetry-scatter}m compared to the NN in figure \ref{fig:nn-if-mean-symmetry-scatter}.

\begin{figure}
\centering
\includegraphics[width=0.7\columnwidth]{img/rf_if_mean_symmetry.png}
\caption{RF prediction certainty scatter plot of mean symmetry.}
\label{fig:rf-if-mean-symmetry-scatter}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.7\columnwidth]{img/nn_if_mean_symmetry.png}
\caption{NN prediction certainty scatter plot of mean symmetry.}
\label{fig:nn-if-mean-symmetry-scatter}
\end{figure}

\section{Regression Example}

A similar method as with the classification was applied to the Boston House Price dataset \cite{bostonhouse} (also provided by Scikit). This dataset has 14 dimensions, where the target is to predict the house price based off of quantitative factors such as age of the house, the number of rooms, and the per capita crime rate of the town within which it is situated. Some interesting relations are made immediately available from the LDR, shown in figure \ref{fig:reg-rf-if-matrix}, are

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{img/reg_rf_if_matrix.png}
\caption{Regression RF with IF interpolation. AGE is the age of the house, RM the number of rooms, and CRIM the per capita crime rate per town.}
\label{fig:reg-rf-if-matrix}
\end{figure}

\begin{enumerate}
\item An increasing crime rate tends to correlated with houses being worth less. Above the median level of crime however, the model becomes uncertain.
\item Any quantity of crime only has a negative effect on house price.
\item The lower the crime rate, the more rooms a house tends to have, and the more it is worth.
\item The older the house, the less it tends to be worth.
\end{enumerate}

The prediction certainty prior to be binning can be seen in figure \ref{fig:reg-rf-if-rm}.

\begin{figure}
\centering
\includegraphics[width=0.7\columnwidth]{img/reg_rf_if_rm.png}
\caption{RF prediction certainty of number of rooms.}
\label{fig:reg-rf-if-rm}
\end{figure}

\section{Mathematical Explanation}

\subsection{Feature Space and Subsets Definition}

Let a scaled feature space $\Omega$ for samples $w = \{0, 1, \ldots, l\}$ be described as

$$\Omega =
\begin{bmatrix}
{\omega_1 = \{d_{1, 1}, d_{2, 1}, \ldots, d_{l, 1}\}} \\
{\omega_2 = \{d_{1, 2}, d_{2, 2}, \ldots, d_{l, 2}\}} \\
\vdots \\
{\omega_m = \{d_{1, m}, d_{2, m}, \ldots, d_{l, m}\}}
\end{bmatrix}
$$

where $d_{i, j} \in [0,1]$, $l$ is the number of features and $m$ is the number of samples in the feature space.

The subset $X$ of values for features $t \subset w$ which are being used to predict a set $Y$ of features $l - t = \{i, (i \in w) \land (i \notin t)\}$ are therefore defined as

$$X =
\begin{bmatrix}
{x_1 = \{d_{1, 1}, d_{2, 1}, \ldots, d_{|t|, 1}\}} \\
{x_2 = \{d_{1, 2}, d_{2, 2}, \ldots, d_{|t|, 2}\}} \\
\vdots \\
{x_m = \{d_{1, m}, d_{2, m}, \ldots, d_{|t|, m}\}}
\end{bmatrix}
$$

$$Y =
\begin{bmatrix}
{y_1 = \{d_{1, 1}, d_{2, 1}, \ldots, d_{|l-t|, 1}\}} \\
{y_2 = \{d_{1, 2}, d_{2, 2}, \ldots, d_{|l-t|, 2}\}} \\
\vdots \\
{y_m = \{d_{1, m}, d_{2, m}, \ldots, d_{|l-t|, m}\}}
\end{bmatrix}
$$

\subsection{(Optional) Model and Outlier Prediction Interpolation }\label{interpolation}

Let $p$ describe a model prediction mapping, such that $p(x_i) \approx y_i$. Let $o$ describe an outlier prediction mapping such that $o(x_i) = [1, 0]$, where $0$ indicates complete certainty of $x_i$ being an outlier and $1$ complete certainty of $x_i$ not being an outlier. Let outlier weighting and model prediction interpolation function $f$ be defined as

$$f(x_i) = (p(x_i) - 0.5) \times o(x_i) + 0.5.$$

\subsection{KDE Sample Drawing}

The KDE with bandwidth $1/r$ can be estimated and $n$ samples drawn from it in unison by drawing from the individual weighting each sample $x \in X$ contributes to the kernel density. This is done by randomly selecting $n$ samples from $X$ and drawing distributed points $q \sim N(x, 1/r)$. This sampling is equivalent to the VEGAS algorithm for the subsequent monte carlo integration \cite{lepage1978new}. The set of samples $Q$ can therefore be described as

$$Q = \{q_1, q_2, \ldots, q_n\}.$$

Note that the VEGAS algorithm relies on the assumption that the sample space is univariate and i.i.d, resulting in LDR only successfully interpreting samples from the same feature space.

\subsection{Monte Carlo Integration Over Feature Subsets}

Let $e$ be the set of intervals describing a single dimensional set of bins, such that

$$e = \{[0, \frac{1}{r}], (\frac{1}{r}, \frac{2}{r}], \ldots, (\frac{r-1}{r}, 1]\}.$$

Let $b \subset t$ describe the feature subspace being interpreted. Let $E$ describe the $|b|$ multivariate permutations of bin pairs, such that

$$E = perm(e_1, e_2, \ldots, e_{|b|}).$$

The Monte Carlo integration of a single point of the feature subset can therefore be described, where $Q_k$ represents all elements that fall within the bin $E_k$, as

$$I_{E_k} = \frac{1}{z} \sum^z_{i=1} f(q_i), q_i \in Q_k.$$

The entire feature subset can be interpreted by applying this for all $E_K \in k$.

\section{Conclusion}\label{Conclusion}

I have demonstrated that it is possible to interpret a models understanding of high dimensional features spaces by estimating the certainty of the model over lower dimensional subsets of the feature space. However, before acceptance for clinical purposes, the model should be rigorously tested on more data sets. In addition to this, further research of extending LDR could be to interpret latent features that do not relate to uninterpretable input features, such as neural networks trained on images; a visualization of the prediction of the model based on a single pixel would not be of much use by itself.

\printbibliography

\end{document}